{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3afb0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running updated function\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import compute_retrieval_metrics\n",
    "importlib.reload(compute_retrieval_metrics)\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "931d280f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------------------------------------------+------------------------------+---------+------------------------------+-----------+\n",
      "|    | Metric                                                   | ASR Count                    | ASR %   | AEGON Count                  | AEGON %   |\n",
      "|----+----------------------------------------------------------+------------------------------+---------+------------------------------+-----------|\n",
      "|  0 | Retrieval Accuracy (Exact)                               | 55                           | 48.25%  | 51                           | 44.74%    |\n",
      "|  1 | Extended Accuracy (Exact + Prefix)                       | 72                           | 63.16%  | 54                           | 47.37%    |\n",
      "|  2 | Recall@1                                                 | 72                           | 63.16%  | 54                           | 47.37%    |\n",
      "|  3 | Precision@1                                              | 72                           | 63.16%  | 54                           | 47.37%    |\n",
      "|  4 | MRR (Mean Reciprocal Rank)                               | Inactive (no retrieved list) | 0.00%   | Inactive (no retrieved list) | 0.00%     |\n",
      "|  5 | MAP (Mean Average Precision)                             | Inactive (no retrieved list) | 0.00%   | Inactive (no retrieved list) | 0.00%     |\n",
      "|  6 | Recall@3                                                 | Inactive (no retrieved list) | 0.00%   | Inactive (no retrieved list) | 0.00%     |\n",
      "|  7 | Precision@3                                              | Inactive (no retrieved list) | 0.00%   | Inactive (no retrieved list) | 0.00%     |\n",
      "|  8 | Hit Rate@3                                               | Inactive (no retrieved list) | 0.00%   | Inactive (no retrieved list) | 0.00%     |\n",
      "|  9 | Coverage (No Match)                                      | 42                           | 36.84%  | 60                           | 52.63%    |\n",
      "| 10 | Misleading Rate (Exact Not Justified)                    | 1                            | 0.88%   | 4                            | 3.51%     |\n",
      "| 11 | Extended Misleading Rate (Exact or Prefix Not Justified) | 18                           | 15.79%  | 4                            | 3.51%     |\n",
      "| 12 | False Positive Rate (Exact)                              | 1                            | 1.82%   | 4                            | 7.84%     |\n",
      "| 13 | False Positive Rate (Extended)                           | 18                           | 25.00%  | 4                            | 7.41%     |\n",
      "| 14 | Justification Rate (All Matches)                         | 69                           | 60.53%  | 63                           | 55.26%    |\n",
      "| 15 | Misleading Coverage (No Match & Not Justified)           | 27                           | 23.68%  | 47                           | 41.23%    |\n",
      "+----+----------------------------------------------------------+------------------------------+---------+------------------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from compute_retrieval_metrics import run_all_metrics_dual\n",
    "\n",
    "df = pd.read_pickle(\"retrieval_eval_results.pkl\")\n",
    "results_df = run_all_metrics_dual(df)\n",
    "\n",
    "print(tabulate(results_df, headers = 'keys', tablefmt= 'psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85749a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running updated function\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import compute_generation_metrics\n",
    "importlib.reload(compute_generation_metrics)\n",
    "from compute_generation_metrics import evaluate_generation_metrics\n",
    "from openai import AzureOpenAI\n",
    "import dotenv \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812e78a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'CreateEmbeddingResponse' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieval_eval_results.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m client \u001b[38;5;241m=\u001b[39m AzureOpenAI(\n\u001b[1;32m      9\u001b[0m         azure_endpoint\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENDPOINT_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     10\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     11\u001b[0m         api_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-05-01-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 14\u001b[0m summary_asr \u001b[38;5;241m=\u001b[39m \u001b[43mgeneration_metric_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m summary_aegon \u001b[38;5;241m=\u001b[39m generation_metric_summary(df, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maegon\u001b[39m\u001b[38;5;124m\"\u001b[39m, client \u001b[38;5;241m=\u001b[39m client)\n\u001b[1;32m     17\u001b[0m summary_asr\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masr_generation_summary.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mgeneration_metric_summary\u001b[0;34m(df, source, client)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgeneration_metric_summary\u001b[39m(df, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masr\u001b[39m\u001b[38;5;124m\"\u001b[39m, client\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     detailed \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_generation_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m detailed\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/sze003-v05221116/code/Users/sze003/repos/test_code/Schade.ClaimAssistantML/sueda_rag_evaluation/evaluation/retrieval/compute_generation_metrics.py:89\u001b[0m, in \u001b[0;36mevaluate_generation_metrics\u001b[0;34m(df, source, client)\u001b[0m\n\u001b[1;32m     86\u001b[0m sys_answer \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mget(sys_col, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m gold_answer \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mget(gold_col, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m sys_emb \u001b[38;5;241m=\u001b[39m \u001b[43membed_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys_answer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m gold_emb \u001b[38;5;241m=\u001b[39m embed_text(gold_answer, client)\n\u001b[1;32m     92\u001b[0m cosine_sim \u001b[38;5;241m=\u001b[39m compute_cosine_similarity(sys_emb, gold_emb)\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/sze003-v05221116/code/Users/sze003/repos/test_code/Schade.ClaimAssistantML/sueda_rag_evaluation/evaluation/retrieval/compute_generation_metrics.py:43\u001b[0m, in \u001b[0;36membed_text\u001b[0;34m(text, client)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEPLOYMENT_NAME_EMBEDDING is missing in .env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m[text],\n\u001b[1;32m     41\u001b[0m     model\u001b[38;5;241m=\u001b[39mdeployment_id,\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding\n",
      "\u001b[0;31mTypeError\u001b[0m: 'CreateEmbeddingResponse' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def generation_metric_summary(df, source=\"asr\", client= None):\n",
    "    detailed = evaluate_generation_metrics(df, source, client)\n",
    "    return detailed.groupby(\"match_type\").mean(numeric_only=True).reset_index()\n",
    " \n",
    "# Evaluation and Save to Excel\n",
    "df = pd.read_pickle(\"retrieval_eval_results.pkl\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        azure_endpoint=os.getenv(\"ENDPOINT_URL\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        api_version=\"2024-05-01-preview\"\n",
    "    )\n",
    " \n",
    "summary_asr = generation_metric_summary(df, source=\"asr\", client=client)\n",
    "summary_aegon = generation_metric_summary(df, source=\"aegon\", client = client)\n",
    " \n",
    "summary_asr.to_excel(\"asr_generation_summary.xlsx\", index=False)\n",
    "summary_aegon.to_excel(\"aegon_generation_summary.xlsx\", index=False)\n",
    " \n",
    "print(\"Generation metric summaries exported.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
